{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567fff29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([  10.  ,   10.25,   11.  , ..., 2000.  , 2200.  , 2912.  ]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m xgb_reg_rmse \u001b[38;5;241m=\u001b[39m rmse(y_test, xgb_reg\u001b[38;5;241m.\u001b[39mpredict(X_test))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Train and evaluate Naive Bayes (GaussianNB)\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m nb\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     81\u001b[0m nb_score \u001b[38;5;241m=\u001b[39m nb\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)  \u001b[38;5;66;03m# Naive Bayes score\u001b[39;00m\n\u001b[0;32m     82\u001b[0m nb_rmse \u001b[38;5;241m=\u001b[39m rmse(y_test, nb\u001b[38;5;241m.\u001b[39mpredict(X_test))  \u001b[38;5;66;03m# RMSE for Naive Bayes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_fit(\n\u001b[0;32m    264\u001b[0m     X, y, np\u001b[38;5;241m.\u001b[39munique(y), _refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[0;32m    265\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:422\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _refit:\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m first_call \u001b[38;5;241m=\u001b[39m _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[0;32m    423\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39mfirst_call)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:421\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` is not the same as on last call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto partial_fit, was: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (classes, clf\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m    417\u001b[0m             )\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;66;03m# This is the first call to partial_fit\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m         clf\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m unique_labels(classes)\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# nothing to do\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:104\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    102\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api_compliant:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([  10.  ,   10.25,   11.  , ..., 2000.  , 2200.  , 2912.  ]),)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LogisticRegressionCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Load dataset\n",
    "path = r\"https://drive.google.com/uc?export=download&id=1P49POlAk27uRzWKXoR2WaEfb1lyyfiRJ\"  # CSV file from Google Drive\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Clean the data\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Split dataset into features and target\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=51)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "lr = LinearRegression()\n",
    "lr_lasso = Lasso()\n",
    "lr_ridge = Ridge()\n",
    "svr = SVR()\n",
    "rfr = RandomForestRegressor()\n",
    "xgb_reg = XGBRegressor()\n",
    "nb = GaussianNB()\n",
    "lr_cv = LogisticRegressionCV(cv=5, max_iter=1000)\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Train and evaluate Linear Regression\n",
    "lr.fit(X_train, y_train)\n",
    "lr_score = lr.score(X_test, y_test)\n",
    "lr_rmse = rmse(y_test, lr.predict(X_test))\n",
    "\n",
    "# Train and evaluate Lasso Regression\n",
    "lr_lasso.fit(X_train, y_train)\n",
    "lr_lasso_score = lr_lasso.score(X_test, y_test)\n",
    "lr_lasso_rmse = rmse(y_test, lr_lasso.predict(X_test))\n",
    "\n",
    "# Train and evaluate Support Vector Machine (SVR)\n",
    "svr.fit(X_train, y_train)\n",
    "svr_score = svr.score(X_test, y_test)\n",
    "svr_rmse = rmse(y_test, svr.predict(X_test))\n",
    "\n",
    "# Train and evaluate Random Forest Regressor\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_score = rfr.score(X_test, y_test)\n",
    "rfr_rmse = rmse(y_test, rfr.predict(X_test))\n",
    "\n",
    "# Train and evaluate XGBoost\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "xgb_reg_score = xgb_reg.score(X_test, y_test)\n",
    "xgb_reg_rmse = rmse(y_test, xgb_reg.predict(X_test))\n",
    "\n",
    "# Train and evaluate Naive Bayes (GaussianNB)\n",
    "nb.fit(X_train, y_train)\n",
    "nb_score = nb.score(X_test, y_test)  # Naive Bayes score\n",
    "nb_rmse = rmse(y_test, nb.predict(X_test))  # RMSE for Naive Bayes\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "lr_cv.fit(X_train, y_train)\n",
    "lr_cv_score = lr_cv.score(X_test, y_test)\n",
    "lr_cv_rmse = rmse(y_test, lr_cv.predict(X_test))\n",
    "\n",
    "# Display the results in a DataFrame\n",
    "results = pd.DataFrame([\n",
    "    {'Model': 'Linear Regression', 'Score': lr_score, 'RMSE': lr_rmse},\n",
    "    {'Model': 'Lasso', 'Score': lr_lasso_score, 'RMSE': lr_lasso_rmse},\n",
    "    {'Model': 'Support Vector Machine', 'Score': svr_score, 'RMSE': svr_rmse},\n",
    "    {'Model': 'Random Forest', 'Score': rfr_score, 'RMSE': rfr_rmse},\n",
    "    {'Model': 'XGBoost', 'Score': xgb_reg_score, 'RMSE': xgb_reg_rmse},\n",
    "    {'Model': 'Naive Bayes', 'Score': nb_score, 'RMSE': nb_rmse},\n",
    "    {'Model': 'Logistic Regression', 'Score': lr_cv_score, 'RMSE': lr_cv_rmse}\n",
    "], columns=['Model', 'Score', 'RMSE'])\n",
    "\n",
    "results\n",
    "\n",
    "# Hyperparameter Tuning for XGBoost (optional, use for optimization)\n",
    "parameters = {'learning_rate': [0.1, 0.03, 0.05, 0.07],\n",
    "              'min_child_weight': [1, 3, 5],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'gamma': [0, 0.1, 0.001, 0.2],\n",
    "              'subsample': [0.7, 1, 1.5],\n",
    "              'colsample_bytree': [0.7, 1, 1.5],\n",
    "              'n_estimators': [100, 300, 500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_reg, parameters, cv=2, n_jobs=-1, verbose=True)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Output the best hyperparameters found through grid search\n",
    "print(\"Best Score:\", xgb_grid.best_score_)\n",
    "print(\"Best Params:\", xgb_grid.best_params_)\n",
    "\n",
    "# Saving the final model (XGBoost)\n",
    "joblib.dump(xgb_reg, 'bangalore_house_price_prediction_model.pkl')\n",
    "\n",
    "# Function to predict house price using the trained model\n",
    "def predict_house_price(model, bath, balcony, total_sqft_int, bhk, price_per_sqft, area_type, availability, location):\n",
    "    x = np.zeros(len(X.columns))  # Create a zero numpy array with length equal to the number of features\n",
    "\n",
    "    # Adding feature values according to their index\n",
    "    x[0] = bath\n",
    "    x[1] = balcony\n",
    "    x[2] = total_sqft_int\n",
    "    x[3] = bhk\n",
    "    x[4] = price_per_sqft\n",
    "\n",
    "    if availability == \"Ready To Move\":\n",
    "        x[8] = 1\n",
    "\n",
    "    if f'area_type{area_type}' in X.columns:\n",
    "        area_type_index = np.where(X.columns == f'area_type{area_type}')[0][0]\n",
    "        x[area_type_index] = 1\n",
    "\n",
    "    if f'location_{location}' in X.columns:\n",
    "        loc_index = np.where(X.columns == f'location_{location}')[0][0]\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    # Feature scaling\n",
    "    x = sc.transform([x])[0]\n",
    "    return model.predict([x])[0]\n",
    "\n",
    "# Test the model prediction\n",
    "predicted_price = predict_house_price(model=xgb_reg, bath=3, balcony=2, total_sqft_int=1672, bhk=3, \n",
    "                                      price_per_sqft=8971.291866, area_type=\"Plot Area\", availability=\"Ready To Move\", \n",
    "                                      location=\"Devarabeesana Halli\")\n",
    "print(\"Predicted House Price:\", predicted_price)\n",
    "\n",
    "# Test the saved model after loading\n",
    "loaded_model = joblib.load(\"bangalore_house_price_prediction_model.pkl\")\n",
    "predicted_price = predict_house_price(model=loaded_model, bath=3, balcony=2, total_sqft_int=1750, bhk=3, \n",
    "                                      price_per_sqft=8571.428571, area_type=\"Super built-up\", availability=\"Ready To Move\", \n",
    "                                      location=\"Devarabeesana Halli\")\n",
    "print(\"Predicted House Price (Loaded Model):\", predicted_price)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
